name: accelerator-wg-workflow-validation

on:
  workflow_dispatch:
    inputs:
      upstream_ref:
        description: 'Ref in pytorch-fdn/accelerator-integration-wg to dispatch'
        required: false
        default: 'main'
  push:
    paths:
      - '.github/workflows/accelerator-wg-workflow-validation.yml'
      - 'scripts/link_accelerator_submodule.sh'
      - 'scripts/dispatch_accelerator_wg_workflows.py'
      - 'docs/accelerator_wg_workflow_validation.md'
  pull_request:
    paths:
      - '.github/workflows/accelerator-wg-workflow-validation.yml'
      - 'scripts/link_accelerator_submodule.sh'
      - 'scripts/dispatch_accelerator_wg_workflows.py'
      - 'docs/accelerator_wg_workflow_validation.md'

permissions:
  contents: read

jobs:
  discover-accelerator-wg-workflows:
    runs-on: ubuntu-latest
    outputs:
      workflow_matrix: ${{ steps.enumerate.outputs.workflow_matrix }}
      workflow_count: ${{ steps.enumerate.outputs.workflow_count }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Enumerate upstream workflow files
        id: enumerate
        shell: bash
        run: |
          set -euo pipefail
          if [[ -z "${{ secrets.ACCELERATOR_WG_GH_TOKEN }}" ]]; then
            echo '[]' > workflow-matrix.json
            echo "workflow_matrix=[]" >> "$GITHUB_OUTPUT"
            echo "workflow_count=0" >> "$GITHUB_OUTPUT"
            echo "No ACCELERATOR_WG_GH_TOKEN provided. Discovery skipped."
            exit 0
          fi

          export GITHUB_TOKEN="${{ secrets.ACCELERATOR_WG_GH_TOKEN }}"
          python scripts/dispatch_accelerator_wg_workflows.py list > workflow-matrix.json

          if [[ ! -s workflow-matrix.json ]]; then
            echo "Failed to discover workflows" >&2
            exit 1
          fi

          matrix_json=$(cat workflow-matrix.json)
          count=$(jq 'length' workflow-matrix.json)

          echo "workflow_matrix=$matrix_json" >> "$GITHUB_OUTPUT"
          echo "workflow_count=$count" >> "$GITHUB_OUTPUT"

      - name: Upload workflow inventory artifact
        uses: actions/upload-artifact@v4
        with:
          name: accelerator-wg-workflow-files
          path: workflow-matrix.json

  execute-accelerator-wg-workflows:
    runs-on: ubuntu-latest
    needs: discover-accelerator-wg-workflows
    if: ${{ needs.discover-accelerator-wg-workflows.outputs.workflow_count != '0' }}
    strategy:
      fail-fast: false
      matrix:
        workflow: ${{ fromJson(needs.discover-accelerator-wg-workflows.outputs.workflow_matrix) }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Dispatch and monitor one upstream workflow
        id: run_one
        shell: bash
        env:
          GITHUB_TOKEN: ${{ secrets.ACCELERATOR_WG_GH_TOKEN }}
          UPSTREAM_REF: ${{ inputs.upstream_ref || 'main' }}
        run: |
          set -euo pipefail
          wid='${{ matrix.workflow.id }}'
          wname='${{ matrix.workflow.name }}'
          wpath='${{ matrix.workflow.path }}'

          out="result-${wid}.json"

          # Always produce result json, even if this step returns non-zero.
          set +e
          python scripts/dispatch_accelerator_wg_workflows.py run-one \
            --ref "$UPSTREAM_REF" \
            --workflow-id "$wid" \
            --workflow-name "$wname" \
            --workflow-path "$wpath" \
            --result-file "$out"
          rc=$?
          set -e

          if [[ ! -s "$out" ]]; then
            jq -n \
              --arg workflow "$wname ($wpath)" \
              --argjson workflow_id "$wid" \
              --arg status "runner_error" \
              --arg note "Script failed before writing result file" \
              '{workflow:$workflow,workflow_id:$workflow_id,run_id:null,status:$status,conclusion:null,note:$note}' > "$out"
          fi

          echo "exit_code=$rc" >> "$GITHUB_OUTPUT"

      - name: Upload per-workflow execution artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: accelerator-wg-run-${{ matrix.workflow.id }}
          path: result-${{ matrix.workflow.id }}.json

      - name: Fail matrix job when workflow execution failed
        if: steps.run_one.outputs.exit_code != '0'
        run: exit 1

  summarize-accelerator-wg-orchestration:
    runs-on: ubuntu-latest
    needs:
      - discover-accelerator-wg-workflows
      - execute-accelerator-wg-workflows
    if: always()
    steps:
      - name: Download execution artifacts
        if: ${{ needs.discover-accelerator-wg-workflows.outputs.workflow_count != '0' }}
        uses: actions/download-artifact@v4
        with:
          pattern: accelerator-wg-run-*
          path: run-results
          merge-multiple: true

      - name: Print orchestration graph and summary
        shell: bash
        run: |
          set -euo pipefail
          echo "Workflow DAG: discover-accelerator-wg-workflows -> execute-accelerator-wg-workflows(matrix) -> summarize-accelerator-wg-orchestration"

          count='${{ needs.discover-accelerator-wg-workflows.outputs.workflow_count }}'
          echo "Discovered upstream workflows: $count"

          if [[ "$count" == "0" ]]; then
            echo "No execution performed (missing token or no workflows found)."
            exit 0
          fi

          python - <<'PY'
          import glob
          import json
          import sys

          files = sorted(glob.glob('run-results/*.json'))
          if not files:
              print('No run result files found', file=sys.stderr)
              sys.exit(1)

          failed = False
          for path in files:
              with open(path, 'r', encoding='utf-8') as f:
                  item = json.load(f)
              print(f"- {item['workflow']}: status={item['status']}, run_id={item.get('run_id')}, conclusion={item.get('conclusion')}, note={item.get('note', '')}")
              if item['status'] in {'not_dispatched', 'timed_out', 'unknown', 'runner_error'}:
                  failed = True
              if item['status'] == 'completed' and item.get('conclusion') != 'success':
                  failed = True

          if failed:
              sys.exit(1)
          PY
